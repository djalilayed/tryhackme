# script generated by Google Gemini Pro
# script for tryhackme room Security Footage https://tryhackme.com/room/securityfootage
# script read images from a folder, use Google Cloud Vision API to extract / detect text from images
# use: python3 p4.py images -n 10 (images is image folder, -n 10 check only 10 images. Google Cloud vision API is free for 1000 unit use)

import os
import argparse
from google.cloud import vision

def get_bounding_box_height(vertices):
    """Helper function to calculate the height of a bounding box."""
    if not vertices or len(vertices) < 2: # Need at least two points to define a span
        return 0
    min_y = min(vertex.y for vertex in vertices if vertex.y is not None)
    max_y = max(vertex.y for vertex in vertices if vertex.y is not None)
    return max_y - min_y

def get_bounding_box_area(vertices):
    """Helper function to calculate the area of a bounding box."""
    if not vertices or len(vertices) < 2:
        return 0
    min_x = min(vertex.x for vertex in vertices if vertex.x is not None)
    max_x = max(vertex.x for vertex in vertices if vertex.x is not None)
    min_y = min(vertex.y for vertex in vertices if vertex.y is not None)
    max_y = max(vertex.y for vertex in vertices if vertex.y is not None)
    return (max_x - min_x) * (max_y - min_y)

def reconstruct_text_from_block(block):
    """Helper function to reconstruct the full text from a block's symbols."""
    block_text = ""
    for paragraph in block.paragraphs:
        for word in paragraph.words:
            for symbol in word.symbols:
                block_text += symbol.text
            # Add a space after each word, except if the word ends with certain punctuation
            # or if the next symbol is a line break (not explicitly checked here but could be)
            if word.symbols and word.symbols[-1].property and word.symbols[-1].property.detected_break:
                break_type = word.symbols[-1].property.detected_break.type
                if break_type == vision.TextAnnotation.DetectedBreak.BreakType.LINE_BREAK or \
                   break_type == vision.TextAnnotation.DetectedBreak.BreakType.EOL_SURE_SPACE:
                    pass # No space needed before newline or sure space
                else:
                    block_text += " " # Add space for other breaks like SPACE
            else:
                 block_text += " " # Default add space
    return block_text.strip()


def extract_main_text_from_images_via_blocks(image_folder_path, num_images_to_test, credentials_path=None, min_block_height_threshold=50):
    """
    Detects text in images using fullTextAnnotation and extracts the text from
    the most prominent TEXT block, likely containing the scrolling flag.

    Args:
        image_folder_path (str): Path to the folder containing images.
        num_images_to_test (int): Number of images to process from the folder.
        credentials_path (str, optional): Path to the GCP service account JSON key.
        min_block_height_threshold (int): Minimum height of a block's bounding box
                                          to be considered a candidate for the main text.
    """
    try:
        if credentials_path:
            client = vision.ImageAnnotatorClient.from_service_account_file(credentials_path)
            print(f"Using credentials from: {credentials_path}")
        else:
            client = vision.ImageAnnotatorClient()
            print("Using credentials from GOOGLE_APPLICATION_CREDENTIALS environment variable.")
    except Exception as e:
        print(f"Error initializing Vision AI client: {e}")
        print("Please ensure you have authenticated correctly.")
        return []

    if not os.path.isdir(image_folder_path):
        print(f"Error: Image folder not found at '{image_folder_path}'")
        return []

    all_image_files = [
        f for f in os.listdir(image_folder_path)
        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.webp', '.gif'))
    ]
    all_image_files.sort()

    if not all_image_files:
        print(f"No image files found in '{image_folder_path}'.")
        return []

    images_to_process_names = all_image_files
    if num_images_to_test > 0: # If 0, process all
        images_to_process_names = all_image_files[:num_images_to_test]
    
    print(f"\nFound {len(all_image_files)} images. Will process {len(images_to_process_names)} images.\n")

    all_extracted_main_texts = []

    for image_name in images_to_process_names:
        image_path = os.path.join(image_folder_path, image_name)
        print(f"--- Processing image: {image_name} ---")
        extracted_main_text_for_image = ""

        try:
            with open(image_path, 'rb') as image_file:
                content = image_file.read()
            image = vision.Image(content=content)
            
            # Using text_detection which also populates fullTextAnnotation
            response = client.text_detection(image=image) 

            if response.error.message:
                raise Exception(response.error.message)

            if not response.full_text_annotation or not response.full_text_annotation.pages:
                print("No fullTextAnnotation or pages found.")
                all_extracted_main_texts.append("") # Append empty for this image
                print("-" * 40 + "\n")
                continue

            page = response.full_text_annotation.pages[0]
            candidate_blocks = []

            for i, block in enumerate(page.blocks):
                if block.block_type == vision.Block.BlockType.TEXT: # Only consider TEXT blocks
                    block_text = reconstruct_text_from_block(block)
                    
                    if block.bounding_box and block.bounding_box.vertices:
                        height = get_bounding_box_height(block.bounding_box.vertices)
                        area = get_bounding_box_area(block.bounding_box.vertices)
                        # print(f"  Block {i+1}: \"{block_text}\" (Height: {height}, Area: {area})") # Debug

                        # Heuristics for the main scrolling text block:
                        # 1. Must meet minimum height.
                        # 2. Text should ideally be single-line for a simple scroller.
                        # 3. Text length should be reasonable (not too long, not just 1-2 chars unless that's all).
                        if height >= min_block_height_threshold and \
                           '\n' not in block_text and \
                           len(block_text) > 2 and len(block_text) < 50: # Adjust length constraints
                            candidate_blocks.append({
                                "text": block_text,
                                "height": height,
                                "area": area,
                                "block_index": i
                            })
            
            if candidate_blocks:
                # Select the best candidate block.
                # For scrolling text, it's often the one with largest area or height.
                # Let's prioritize area to find the most substantial text block.
                best_block_candidate = max(candidate_blocks, key=lambda x: x['area'])
                extracted_main_text_for_image = best_block_candidate['text']
                print(f"Extracted main text (from Block {best_block_candidate['block_index']+1}): \"{extracted_main_text_for_image}\" (Area: {best_block_candidate['area']})")
            else:
                print(f"No suitable TEXT block met the criteria for {image_name}.")
                # Fallback: Check response.text_annotations[0] first line as a last resort
                if response.text_annotations:
                    first_line_full = response.text_annotations[0].description.split('\n')[0].strip()
                    if len(first_line_full) > 2 and len(first_line_full) < 50:
                        print(f"  Fallback to first line of textAnnotations[0]: \"{first_line_full}\"")
                        extracted_main_text_for_image = first_line_full


        except FileNotFoundError:
            print(f"Error: Image file not found at {image_path}")
            extracted_main_text_for_image = "ERROR_FILE_NOT_FOUND"
        except Exception as e:
            print(f"An error occurred processing {image_name}: {e}")
            extracted_main_text_for_image = "ERROR_PROCESSING"
        
        all_extracted_main_texts.append(extracted_main_text_for_image)
        print("-" * 40 + "\n")

    print("\n--- Summary of extracted main texts (in order) ---")
    for i, main_text in enumerate(all_extracted_main_texts):
        img_name_to_print = images_to_process_names[i] if i < len(images_to_process_names) else f"Image_{i+1}"
        print(f"{img_name_to_print}: \"{main_text}\"")

    return all_extracted_main_texts

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="Extracts main scrolling text from images using Google Cloud Vision API's block structure."
    )
    parser.add_argument(
        "image_folder", type=str, help="Path to the folder containing images."
    )
    parser.add_argument(
        "-n", "--num_images", type=int, default=0,
        help="Number of images to test from the folder (default: 0 for all images)."
    )
    parser.add_argument(
        "-c", "--credentials", type=str, default=None,
        help="Optional: Path to your GCP service account JSON key file."
    )
    parser.add_argument(
        "--min_block_height", type=int, default=50, # Scrolling text blocks are usually prominent
        help="Minimum bounding box height for a TEXT block to be considered (default: 50 pixels)."
    )
    args = parser.parse_args()

    extracted_texts = extract_main_text_from_images_via_blocks(
        args.image_folder,
        args.num_images,
        args.credentials,
        args.min_block_height
    )
    # Further processing of `extracted_texts` (like flag reconstruction) would go here.
